---
title: "automatization_notebook"
author: "Anna Andreychenko"
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
library(dplyr)
library(tidyr)
library(purrr)
library(lubridate)
library(flextable)
library(infer)
library(corrplot)
library(corrr)
library(reshape2)
library(RColorBrewer)
library(ggbeeswarm)

# самописные функции
outliers <- function(dataframe){
dataframe %>%
     select_if(is.numeric) %>% 
      map(~ boxplot.stats(.x)$out) 
  }


```

# Чтение данных

В вашем варианте нужно использовать датасеты cardio_train_big или cardio_train_not_too_big.

```{r}

read.csv2("data/raw/cardio_train_big.csv", dec=".") -> original_data
original_data |> head()


```

# Выведите общее описание данных

```{r}
glimpse(original_data)
```

```{r, echo = FALSE, results = 'hide'}
sum(is.na(original_data))
```


# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

**Обоснование**: Выбрала оба варианта: 1. Оставляем записи с не менее 50% переменных. 2. Осталяем переменные заполненные в более 20% записей

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4) Отсортируйте данные по возрасту по убыванию;

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6) Присвойте получившийся датасет переменной "cleaned_data".

```{r}

original_data[which(rowMeans(!is.na(original_data)) > 0.5), which(colMeans(!is.na(original_data)) > 0.2)] %>%
  rename_with(function(x) x %>% 
                str_replace("ap_hi", "systolic_blood_pressure") %>% 
                str_replace("ap_lo", "diastolic_blood_pressure") %>% 
                str_replace("gluc", "glucose") %>%
                str_replace("active", "physical_activity")) %>%
  mutate(across(c(gender,smoke,alco,physical_activity,cardio), function(x) as.factor(x))) %>%
  mutate(across(!c(id, gender,smoke,alco,physical_activity,cardio), function(x) as.numeric(x))) %>%
  arrange(desc(age)) -> cleaned_data

outliers1 <- outliers(cleaned_data)
temp <- list()
for (col in names(outliers1)) {
  outlier <- outliers1[[col]]
  if (length(outlier) > 0) {
    temp <- cleaned_data[which(cleaned_data[[col]] %in% outlier),]
  } 
}
temp <- temp[!duplicated(temp$id),]
write.csv2(temp, "data/outliers.csv")
rm(temp, outliers1, col, outlier)

  


```

# Сколько осталось переменных?

```{r}
cleaned_data |> ncol()


```

# Сколько осталось случаев?

```{r}
cleaned_data |> nrow()


```

# Есть ли в данных идентичные строки?

```{r}
print("Кол-во идентичных строк c учетом id")
sum(as.numeric(duplicated(cleaned_data))) 
print("Кол-во идентичных строк без учета id")
sum(as.numeric(duplicated(cleaned_data[,-1]))) 


```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
#
#cleaned_data[2:5,3:4] <- NA
print("Кол-во переменных с пропущенными значениями")
print(length(names(cleaned_data)[sapply(cleaned_data, anyNA)]))
print("Кол-во пропущенных значений в каждой такой переменной")
colSums(is.na(cleaned_data[sapply(cleaned_data, anyNA)]))

  

```

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (наличие или отсутствие сердечно-сосудистых заболеваний):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
statistics <- list(
      `_Количество значений` = ~length(.x) %>% as.character(),
      `_Количество пропущенных значений` = ~sum(is.na(.x)) %>% as.character(),
      `_Среднее` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_25% квантиль и 75% квантиль` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2), " и ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2))),
      `_Интерквартильный размах` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*",
IQR(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_Минимум` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*",
  min(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_Максимум` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*",
  max(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `_95% ДИ для среднего` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", paste0((mean(.x, na.rm = TRUE) - qt(0.975, df = length(.x) - 1)*sd(.x, na.rm = TRUE)/sqrt(length(.x))) %>% round(2), " - ", (mean(.x, na.rm = TRUE) + qt(0.975, df = length(.x) - 1)*sd(.x, na.rm = TRUE)/sqrt(length(.x))) %>% round(2)))

                                  
)

cleaned_data %>%
  select(cardio, where(is.numeric)) %>%
  group_by(cardio) %>%
  summarize(across(where(is.numeric) & !c(id), statistics)) %>%
  pivot_longer(!cardio) %>%
  separate(name, into = c("Variable", "Statistics"), sep = "__") %>%
  mutate(cardio = factor(cardio, levels=c(0,1), labels=c("Нет", "Да"))) %>%
  rename (Value = value, "Наличие ССЗ" =  cardio) %>%
  flextable() %>% merge_v(, j=c("Наличие ССЗ", "Variable")) %>%
  autofit()
  


```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (наличие или отсутствие сердечно-сосудистых заболеваний):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}
CI_categ <- function(t){
tb <- prop.table(table(t))
n <- length(t)
result <- ''
for (i in names(tb)) {
  p<- tb[i]
  result <- paste0(result, toString(paste0((p - qnorm(0.975)*sqrt(p*(1-p)/n)) %>% round(2),"-",(p + qnorm(0.975)*sqrt(p*(1-p)/n)) %>% round(2))), ", ")
}
return(substr(result,1, nchar(result)-2))
}


statistics_categ <- list(
      `_Абсолютное количество` = ~length(.x) %>% as.character(),
      `_Количество пропущенных значений` = ~sum(is.na(.x)) %>% as.character(),
      `_Группы` = ~ toString(names(prop.table(table(.x)))),
      `_Относительное количество внутри группы` = ~toString(as.numeric(prop.table(table(.x)) %>% round(2))),
      `_95% ДИ для долей` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", CI_categ(.x))
)

cleaned_data %>%
  select(cardio, where(is.factor)) %>%
  group_by(cardio) %>%
  reframe(across(where(is.factor), statistics_categ)) %>%
  pivot_longer(!cardio) %>%
  separate(name, into = c("Variable", "Statistics"), sep = "__") %>%
  mutate(cardio = factor(cardio, levels=c(0,1), labels=c("Нет", "Да"))) %>%
  rename (Value = value, "Наличие ССЗ" =  cardio) %>%
  flextable() %>% merge_v(, j=c("Наличие ССЗ", "Variable")) %>%
  autofit()


```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r, fig.width=14, fig.height = 14}


cleaned_data[1:100,] |> 
  select(cardio, where(is.numeric)) |> 
  mutate(cardio = factor(cardio, levels=c(0,1), labels=c("Нет", "Да"))) |>
  melt(id=c('id','cardio')) |>
  ggplot()+
  #geom_beeswarm(aes(x=cardio, y=value), method = "hex") +
  geom_boxplot(aes(x=cardio, y=value, fill = cardio), outliers = FALSE, show.legend=FALSE)+
  scale_fill_brewer(palette = "YlOrRd") +
  scale_x_discrete(name = "Наличие ССЗ")+
  facet_wrap(vars(variable), scales = "free_y")
  




```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r, fig.width = 8}
cleaned_data |> 
  select(id, cardio, where(is.factor)) |> 
  mutate(cardio = factor(cardio, levels=c(0,1), labels=c("Нет", "Да"))) |>
  melt(id=c('id','cardio')) |>
  ggplot()+
  geom_bar(aes(x = fct_infreq(cardio), 
               fill = value), 
           position = "fill")+ 
  scale_x_discrete(name = "Наличие ССЗ")+
  labs(y = "Доля", title="Пропорции категориальных переменных", subtitle=  "в зависимости от наличия ССЗ")+
  facet_wrap(vars(variable))+
  scale_fill_discrete(name = "Категории", labels = c("Нет", "Да/Мужской пол", "Женски пол"))+

  theme_classic()


```

**Для визуализации пропорций подходят отнормированные столбики, наглядно демонстрирующие разницу в относительных долях каждой категории между группами.** 

# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
cleaned_data[sample(5000),] |> 
  select(where(is.numeric) & !c(id)) |> lapply(shapiro.test) |>
  sapply(`[`, c("statistic","p.value")) |> t()




```

**Ответ:** Ни одна из численных переменных не имеет нормальное распределение.

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r, fig.width=14}
cleaned_data[sample(5000),] |> 
  select(where(is.numeric)) |>
  melt(id=c('id')) |>
  ggplot()+
  geom_qq(aes(sample = value))+
  facet_wrap(vars(variable), scales = "free_y")
  


```

Согласно QQ-графику приближенное к нормальному распределению имеют переменные возраст и рост. Предпочла бы графический метод, так как у него нет ограничений на объем выборки и визуально можно оценить "нормальность".


3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Еще есть метод Колмогорова-Смирнова, метод Андерсона-Дарлинга, метод Д'Агостино-Пирсона. Метод Колмогорова-Смирнова считается более подходящим для больших выборок, метод Андерсона-Дарлинга является неспецифическим к форме распределения, метод Д'Агостино следует применять, когда нет сведений об альтернативном распределении. Он показывает хорошую мощность против большого спектра альтернатив, по мощности немного уступая критерию Шапиро - Уилка.**




## Сравнение групп

1) Сравните группы (переменная **cardio**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}

t.test(age~cardio, cleaned_data)
t.test(height~cardio, cleaned_data)  
wilcox.test(weight~cardio,cleaned_data)
wilcox.test(systolic_blood_pressure~cardio,cleaned_data)
wilcox.test(diastolic_blood_pressure~cardio,cleaned_data)
wilcox.test(cholesterol~cardio,cleaned_data)
wilcox.test(glucose~cardio,cleaned_data)

chisq.test(cleaned_data$gender, cleaned_data$cardio)
chisq.test(cleaned_data$smoke, cleaned_data$cardio)
chisq.test(cleaned_data$alco, cleaned_data$cardio)
chisq.test(cleaned_data$physical_activity, cleaned_data$cardio)

```
**Для нормально распределенных переменных был выбран t-test.
Для ненормально распределенных переменных был выбран критерий критерий Манна-Уитни.
Для категориальных переменных был выбран критерий хи-квадрат.**

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r, fig.width=10, fig.height=10}

cleaned_data |> 
  select(where(is.numeric) & !c(id)) |>
  psych::corr.test(adjust = "bonferroni") -> cor_results
  
corrplot(cor_results$r, method = 'color', col = COL2('RdBu', 10))
  


```


**Корреляционные матрицы удобно использовать для обобщения большого набора данных с большим числом количественных и ранговых переменных.
Преимущества: результаты корреляционного анализа служат основой для идей и гипотез о взаимосвязях в данных. 
Недостатки: корреляционный анализ не позволяет определить причину взаимосвязи между двумя переменными.**



## Моделирование

1) Постройте регрессионную модель для переменной **cardio**. Опишите процесс построения

```{r}
library(caTools)
library(ROCR)

split <- sample.split(cleaned_data, SplitRatio = 0.8)

 
train_reg <- subset(cleaned_data, split == "TRUE")
test_reg <- subset(cleaned_data, split == "FALSE")

# Training model
logistic_model <- glm(cardio ~ age + gender + height + weight + systolic_blood_pressure + diastolic_blood_pressure + cholesterol + glucose + smoke + alco + physical_activity,
                    data = train_reg,
                    family = "binomial")
logistic_model
 
# Summary
summary(logistic_model)

predict_reg <- predict(logistic_model,
                       test_reg, type = "response")
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$cardio)
ROCPer <- performance(ROCPred, measure = "tpr",
                      x.measure = "fpr")
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
 
# Plotting curve
plot(ROCPer, colorize = TRUE,
     print.cutoffs.at = seq(0.1, by = 0.1),
     main = "ROC CURVE")
abline(a = 0, b = 1)
 
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)



```


**Процесс построения модели:
1. Выбор линейной либо логистической регрессии.
2. Разделение данных на обучающую и тестовую выборки.
3. Построение модели.
4. Оценка модели на тестовой выборке.**




